{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file_path):   \n",
    "\n",
    "    wav, sr = librosa.load(file_path, sr=44100)\n",
    "    sample_num = 44100\n",
    "    data = []\n",
    "\n",
    "    step_num = int((44100 * 1) /2)\n",
    "    # hop_length = 44100 // 50\n",
    "    hop_length = 44100 // 50\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    ind = 0\n",
    "    while ind + step_num + step_num <= wav.shape[0]:\n",
    "        frame = wav[ind:ind+step_num+step_num]\n",
    "        ind = ind + step_num\n",
    "        count = count + 1\n",
    "            \n",
    "        melspec = librosa.feature.melspectrogram(y=frame, sr=44100, hop_length=hop_length, n_mels = 64)\n",
    "        melspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "        \n",
    "        #logamplitude = librosa.amplitude_to_db(melspec)\n",
    "        #mfcc = librosa.feature.mfcc(S=logamplitude, n_mfcc=13)\n",
    "        #zcr = librosa.feature.zero_crossing_rate(y=frame,frame_length=44100, hop_length=hop_length, center=True)\n",
    "        #rms = librosa.feature.rms(y=frame, S=None, frame_length=44100, hop_length=hop_length, center=True, pad_mode='constant')\n",
    "        #sc = librosa.feature.spectral_centroid(y=frame, sr=44100, S=None, n_fft=44100, hop_length=hop_length, freq=None, win_length=None, window='hann', center=True, pad_mode='constant')\n",
    "        #sb = librosa.feature.spectral_bandwidth(y=frame, sr=44100, S=None, n_fft=44100, hop_length=hop_length, win_length=None, window='hann', center=True, pad_mode='constant', freq=None, centroid=None, norm=True, p=2)\n",
    "        #srp = librosa.feature.spectral_rolloff(y=frame, sr=44100, S=None, n_fft=44100, hop_length=hop_length, win_length=None, window='hann', center=True, pad_mode='constant', freq=None, roll_percent=0.85)\n",
    "        #chroma = librosa.feature.chroma_stft(y=frame, sr=44100, S=None, norm=np.inf, n_fft=44100, hop_length=hop_length, win_length=None, window='hann', center=True, pad_mode='constant', tuning=None, n_chroma=12)\n",
    "        #sct = librosa.feature.spectral_contrast(y=frame, sr=44100, S=None, n_fft=44100, hop_length=hop_length, win_length=None, window='hann', center=True, pad_mode='constant', freq=None, fmin=200.0, n_bands=6, quantile=0.02, linear=False)\n",
    "            \n",
    "        #print(melspec.shape)\n",
    "        m1 = np.mean(melspec,axis = 1)\n",
    "        m2 = np.std(melspec,axis = 1)\n",
    "            \n",
    "        #print(mfcc.shape)\n",
    "        #f1 = np.mean(mfcc,axis = 1)\n",
    "        #f2 = np.std(mfcc,axis = 1)\n",
    "            \n",
    "        #print(zcr.shape)\n",
    "        #f3 = np.mean(zcr,axis = 1)\n",
    "        #f4 = np.std(zcr,axis = 1)\n",
    "\n",
    "        #print(rms.shape)\n",
    "        #f5 = np.mean(rms,axis = 1)\n",
    "        #f6 = np.std(rms,axis = 1)\n",
    "            \n",
    "        #print(sc.shape)\n",
    "        #f7 = np.mean(sc,axis = 1)\n",
    "        #f8 = np.std(sc,axis = 1)\n",
    "            \n",
    "        #print(sb.shape)\n",
    "        #f9 = np.mean(sb,axis = 1)\n",
    "        #f10 = np.std(sb,axis = 1)\n",
    "            \n",
    "        #print(srp.shape)\n",
    "        #f11 = np.mean(srp,axis = 1)\n",
    "        #f12 = np.std(srp,axis = 1)\n",
    "            \n",
    "        #print(chroma.shape)\n",
    "        #f13 = np.mean(chroma,axis = 1)\n",
    "        #f14 = np.std(chroma,axis = 1)\n",
    "            \n",
    "        #print(sct.shape)\n",
    "        #f15 = np.mean(sct,axis = 1)\n",
    "        #f16 = np.std(sct,axis = 1)\n",
    "            \n",
    "        feature_list = [m1,m2]\n",
    "        features = np.concatenate([feature.flatten() for feature in feature_list])\n",
    "    \n",
    "        data.append(features)\n",
    "        # print(count)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "out_col = 'category'\n",
    "in_col = 'filename'\n",
    "c2i = {}\n",
    "i2c = {}\n",
    "num_classes = 10\n",
    "df = df[df['esc10']]\n",
    "categories = sorted(df[out_col].unique())\n",
    "for i, category in enumerate(categories):\n",
    "    c2i[category] = i\n",
    "    i2c[i] = category\n",
    "        \n",
    "folder_path = 'ESC-50-master/audio'\n",
    "for ind in tqdm(range(len(df))):\n",
    "    row = df.iloc[ind]\n",
    "    file_path = os.path.join(folder_path, row[in_col])\n",
    "    new_data = get_features(file_path)\n",
    "    new_label = [c2i[row['category']]] * len(new_data)\n",
    "    all_data.extend(new_data)\n",
    "    all_labels.extend(new_label)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "  all_data[i] = all_data[i].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# with open('Xtrain.json', 'w') as json_file:\n",
    "#     json.dump(X_train, json_file, indent=4)\n",
    "# with open('Xtest.json', 'w') as json_file:\n",
    "#     json.dump(X_test, json_file, indent=4)\n",
    "# with open('Ytrain.json', 'w') as json_file:\n",
    "#     json.dump(y_train, json_file, indent=4)\n",
    "# with open('Ytest.json', 'w') as json_file:\n",
    "#     json.dump(y_test, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto',kernel='linear'))\n",
    "clf.fit(X_train, y_train)\n",
    "sum(clf.predict(X_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_random_projection:\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.init_projection()\n",
    "\n",
    "    def init_projection(self):\n",
    "        self.projection = np.random.normal(0, 1, size=(self.out_dim, self.in_dim))\n",
    "        self.projection = np.sign(self.projection)\n",
    "\n",
    "    def encode(self,x):\n",
    "        enc = self.projection @ x\n",
    "        enc = enc.squeeze()\n",
    "        return np.sign(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hd_model:\n",
    "    def __init__(self,X_train, X_test, y_train, y_test ,in_dim,out_dim,lr):\n",
    "        \n",
    "        scaler = StandardScaler() \n",
    "        scaler.fit(X_train)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.X_train = scaler.transform(X_train)\n",
    "        self.X_test = scaler.transform(X_test)\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.lr = lr\n",
    "\n",
    "        self.encoder = linear_random_projection(self.in_dim,self.out_dim)\n",
    "        self.class_hvs = np.zeros((10,self.out_dim))\n",
    "        \n",
    "        self.train_encs = []\n",
    "    \n",
    "    def train_(self):\n",
    "        n_train = len(self.X_train)\n",
    "        for i in range(n_train):\n",
    "            sample = self.X_train[i]\n",
    "            label = self.y_train[i]\n",
    "            enc = self.encoder.encode(sample)  \n",
    "            similarities = cosine_similarity(enc.reshape(1, -1), self.class_hvs)[0]\n",
    "            pred = np.argmax(similarities)\n",
    "            # self.class_hvs[label] += 2 * (1-similarities[label]) * enc\n",
    "            # self.class_hvs[pred] -= 2 * (1-similarities[pred]) * enc\n",
    "            self.class_hvs[label] += enc\n",
    "            self.class_hvs[pred] -= enc\n",
    "            self.train_encs.append(enc)\n",
    "\n",
    "    \n",
    "    def test_(self):\n",
    "        preds = []\n",
    "                           \n",
    "        n_test = len(self.X_test)\n",
    "        for i in range(n_test):\n",
    "            sample = self.X_test[i]\n",
    "            label = self.y_test[i]\n",
    "            enc = self.encoder.encode(sample)\n",
    "            similarities = cosine_similarity(enc.reshape(1, -1), self.class_hvs)[0]\n",
    "            pred = np.argmax(similarities)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        print(\"================================\")\n",
    "        print(accuracy_score(self.y_test, preds))\n",
    "        print(f1_score(self.y_test, preds, average=\"weighted\"))\n",
    "        cm = confusion_matrix(self.y_test, preds,labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "        print(cm)\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        print(\"================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def retrain(self):\n",
    "        for e in range(4):\n",
    "            count = 0\n",
    "            print(e)\n",
    "            for i in range(len(self.train_encs)):\n",
    "                enc = self.train_encs[i]\n",
    "                label = self.y_train[i]\n",
    "                similarities = cosine_similarity(enc.reshape(1, -1), self.class_hvs)[0]\n",
    "                pred = np.argmax(similarities)\n",
    "                if pred != label:\n",
    "                    # self.class_hvs[label] += self.lr * (1-similarities[label]) * enc\n",
    "                    # self.class_hvs[pred] -= self.lr * (1-similarities[pred]) * enc\n",
    "                    self.class_hvs[label] += enc\n",
    "                    self.class_hvs[pred] -= enc\n",
    "                    count += 1\n",
    "            print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hd_model(X_train, X_test, y_train, y_test,128,1000,0.75)\n",
    "with open('projection.json', 'w') as json_file:\n",
    "    json.dump(model.encoder.projection.tolist(), json_file, indent=4)\n",
    "with open('Xtrain.json', 'w') as json_file:\n",
    "    json.dump(model.X_train.tolist(), json_file, indent=4)\n",
    "with open('Xtest.json', 'w') as json_file:\n",
    "    json.dump(model.X_test.tolist(), json_file, indent=4)\n",
    "with open('Ytrain.json', 'w') as json_file:\n",
    "    json.dump(y_train, json_file, indent=4)\n",
    "with open('Ytest.json', 'w') as json_file:\n",
    "    json.dump(y_test, json_file, indent=4)\n",
    "model.train_()\n",
    "model.test_()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_array_str = \"float x_train[][] = {\\n\"\n",
    "for row in model.X_train:\n",
    "    row_str = \", \".join(map(str, row))\n",
    "    c_array_str += f\"    {{{row_str}}},\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "with open('X_train.txt', 'w') as file:\n",
    "    file.write(c_array_str)\n",
    "\n",
    "c_array_str = \"float x_test[][] = {\\n\"\n",
    "for row in model.X_test:\n",
    "    row_str = \", \".join(map(str, row))\n",
    "    c_array_str += f\"    {{{row_str}}},\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "with open('X_test.txt', 'w') as file:\n",
    "    file.write(c_array_str)\n",
    "\n",
    "c_array_str = \"signed char y_train[] = {\\n\"\n",
    "for row in model.y_train:\n",
    "    c_array_str += str(row)\n",
    "    c_array_str += \"\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "with open('Y_train.txt', 'w') as file:\n",
    "    file.write(c_array_str)\n",
    "\n",
    "c_array_str = \"signed char y_test[] = {\\n\"\n",
    "for row in model.y_test:\n",
    "    c_array_str += str(row)\n",
    "    c_array_str += \"\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "with open('Y_test.txt', 'w') as file:\n",
    "    file.write(c_array_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import array\n",
    "# import struct\n",
    "\n",
    "\n",
    "# #bit_array_projection = [array.array('B', [0] * (model.in_dim // 8)) for _ in range(model.out_dim)]\n",
    "\n",
    "# #type(0b10000000)\n",
    "# bit_array_projection = [[0]*(model.in_dim//8)]*model.out_dim\n",
    "# for i in range(model.out_dim):\n",
    "#     for j in range(model.in_dim//8):\n",
    "#         bit_array_projection[i][j] = struct.pack('B', 0)\n",
    "\n",
    "# print(type(bit_array_projection[0][0]))\n",
    "\n",
    "# for i in range(model.out_dim):\n",
    "#     for j in range(model.in_dim):\n",
    "#         if model.encoder.projection[i][j]==1:\n",
    "#             print('i: ', i)\n",
    "#             print('j: ', j)\n",
    "#             print((int(model.encoder.projection[i][j//8])))\n",
    "#             print((0b10000000 >> (j % 8)))\n",
    "#             print((int(model.encoder.projection[i][j//8])) | (0b10000000 >> (j % 8)))\n",
    "#             bit_array_projection[i][j//8] = struct.pack('B', (int(model.encoder.projection[i][j//8])) | (0b10000000 >> (j % 8)) % 256) \n",
    "#         else:\n",
    "#             bit_array_projection[i][j//8] =  struct.pack('B', (int(model.encoder.projection[i][j//8])) & (~(0b10000000 >> (j % 8))) % 256)\n",
    "\n",
    "# for i in range(model.out_dim):\n",
    "#     for j in range(model.in_dim):\n",
    "#         byte_index = j // 8\n",
    "#         bit_index = j % 8\n",
    "#         byte_value = np.frombuffer(bit_array_projection[i, byte_index], dtype=np.uint8)[0]\n",
    "#         if model.encoder.projection[i, j//8] == 1:\n",
    "#             new_byte_value = model.encoder.projection[i, j//8] | (0b10000000 >> bit_index)\n",
    "#         else:\n",
    "#             new_byte_value = model.encoder.projection[i, j//8] & (~(0b10000000 >> bit_index))\n",
    "#         bit_array_projection[i, byte_index] = np.chararray.tobytes(np.array([new_byte_value], dtype=np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(len(model.encoder.projection)):\n",
    "    temp2 = []\n",
    "    for j in range(len(model.encoder.projection[0])//8):\n",
    "        a = 0\n",
    "        for k in range(8):\n",
    "            a = a * 2\n",
    "            if (model.encoder.projection[i][j*8+7-k] > 0):\n",
    "                a = a + 1\n",
    "        temp2.append(a)\n",
    "            #print(a)\n",
    "    temp.append(temp2)\n",
    "    \n",
    "# temp = temp.astype(int).tolist()\n",
    "\n",
    "c_array_str = \"signed char projection[][] = {\\n\"\n",
    "\n",
    "for row in temp:\n",
    "    row_str = \", \".join(map(str, row))\n",
    "    c_array_str += f\"    {{{row_str}}},\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "with open('projection.txt', 'w') as file:\n",
    "    file.write(c_array_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('projection.json', 'w') as json_file:\n",
    "    json.dump(model.encoder.projection.tolist(), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.retrain()\n",
    "model.test_()\n",
    "class_hvs_int = model.class_hvs.astype(int).tolist()\n",
    "c_array_str = \"signed char class_hvs[][] = {\\n\"\n",
    "for row in class_hvs_int:\n",
    "    row_str = \", \".join(map(str, row))\n",
    "    c_array_str += f\"    {{{row_str}}},\\n\"\n",
    "c_array_str += \"};\"\n",
    "\n",
    "# Write the C array string to a text file\n",
    "with open('class_hvs.txt', 'w') as file:\n",
    "    file.write(c_array_str)\n",
    "    \n",
    "# with open('class_hvs.txt', 'w') as json_file:\n",
    "#     json.dump(model.class_hvs.astype(int).tolist(), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_class_hvs = np.array(model.class_hvs)\n",
    "\n",
    "# for hypervector in array_class_hvs:\n",
    "    # pruned_hyperfector = hypervector[hypervector >= ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
